{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ocanaydin/animal-classify-tfl?scriptVersionId=113934637\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_dir = \"../input/animals10/raw-img\"\nimport tensorflow as tf\nimport pathlib\n!pip install split-folders","metadata":{"execution":{"iopub.status.busy":"2022-08-05T08:49:20.982133Z","iopub.execute_input":"2022-08-05T08:49:20.983238Z","iopub.status.idle":"2022-08-05T08:49:36.648083Z","shell.execute_reply.started":"2022-08-05T08:49:20.983188Z","shell.execute_reply":"2022-08-05T08:49:36.646818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SPLIT DATA AS TRAIN AND VALIDATION**","metadata":{}},{"cell_type":"code","source":"import splitfolders\ndef split_data(data_path):\n    data = pathlib.Path(data_path)\n    splitfolders.ratio(data,output = \"../outputs/Images/\",seed = 42,ratio = (0.8,0.2),group_prefix = None)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T08:49:36.65175Z","iopub.execute_input":"2022-08-05T08:49:36.653293Z","iopub.status.idle":"2022-08-05T08:49:36.664446Z","shell.execute_reply.started":"2022-08-05T08:49:36.653245Z","shell.execute_reply":"2022-08-05T08:49:36.663415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split_data(images_dir)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T08:49:43.148806Z","iopub.execute_input":"2022-08-05T08:49:43.149535Z","iopub.status.idle":"2022-08-05T08:52:54.423556Z","shell.execute_reply.started":"2022-08-05T08:49:43.149495Z","shell.execute_reply":"2022-08-05T08:52:54.422415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**PRE PROCESSING OF IMAGES**","metadata":{}},{"cell_type":"code","source":"\"\"\"All images will be scaled with 1./255 to normalize between 0-1.\"\"\"\ntrain_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\nvalidation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T08:52:58.934118Z","iopub.execute_input":"2022-08-05T08:52:58.935172Z","iopub.status.idle":"2022-08-05T08:53:00.054585Z","shell.execute_reply.started":"2022-08-05T08:52:58.935115Z","shell.execute_reply":"2022-08-05T08:53:00.053514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\"../outputs/Images/train\",target_size = (150,150),\n                                                   class_mode = \"categorical\",batch_size = 32,seed=42)\nvalidation_generator = validation_datagen.flow_from_directory(\"../outputs/Images/val\",target_size = (150,150),\n                                                             class_mode = \"categorical\",batch_size = 32,\n                                                              shuffle = False,seed = 42)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T08:53:00.058393Z","iopub.execute_input":"2022-08-05T08:53:00.058687Z","iopub.status.idle":"2022-08-05T08:53:01.450824Z","shell.execute_reply.started":"2022-08-05T08:53:00.058659Z","shell.execute_reply":"2022-08-05T08:53:01.449564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**CNN ARCHITECTURE**","metadata":{}},{"cell_type":"markdown","source":"**SEPERABLE 2D CONVOLUTION**","metadata":{}},{"cell_type":"code","source":"model = tf.keras.models.Sequential()\n\"\"\"(1)Convolution and batch normalization.\"\"\"\nmodel.add(tf.keras.layers.SeparableConv2D(32,(3,3),input_shape = (150,150,3)))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Activation(\"relu\"))\n\"\"\"(2)Convolution and batch normalization.\"\"\"\nmodel.add(tf.keras.layers.SeparableConv2D(64,(3,3)))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Activation(\"relu\"))\n\"\"\"(3)Convolution and batch normalization.\"\"\"\nmodel.add(tf.keras.layers.SeparableConv2D(32,(3,3)))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Activation(\"relu\"))\n\"\"\"Fully connected layer and dropout.\"\"\"\nmodel.add(tf.keras.layers.GlobalAveragePooling2D())\nmodel.add(tf.keras.layers.Dense(256,activation = \"relu\"))\nmodel.add(tf.keras.layers.Dropout(0.3))\n\"\"\"Output layer\"\"\"\nmodel.add(tf.keras.layers.Dense(10,activation = \"relu\"))","metadata":{"execution":{"iopub.status.busy":"2022-08-05T08:54:41.215722Z","iopub.execute_input":"2022-08-05T08:54:41.216083Z","iopub.status.idle":"2022-08-05T08:54:41.313663Z","shell.execute_reply.started":"2022-08-05T08:54:41.216052Z","shell.execute_reply":"2022-08-05T08:54:41.312771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-05T08:54:41.902443Z","iopub.execute_input":"2022-08-05T08:54:41.902814Z","iopub.status.idle":"2022-08-05T08:54:41.911363Z","shell.execute_reply.started":"2022-08-05T08:54:41.902784Z","shell.execute_reply":"2022-08-05T08:54:41.910331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**TRANSFER LEARNING ARCHITECTURE**","metadata":{}},{"cell_type":"markdown","source":"**(1)Use Xception as base model**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.xception import Xception\nbase_model = Xception(include_top = False,weights = \"imagenet\",input_shape = (150,150,3),pooling = \"max\")\n\"\"\"Freeze layers to stop updating the weights of Xception.\"\"\"\nfor layer in base_model.layers:\n    layer.trainable = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-03T16:26:39.741056Z","iopub.execute_input":"2022-08-03T16:26:39.741425Z","iopub.status.idle":"2022-08-03T16:26:39.767538Z","shell.execute_reply.started":"2022-08-03T16:26:39.741389Z","shell.execute_reply":"2022-08-03T16:26:39.766281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**(2)Create an architecture to feed model.**","metadata":{}},{"cell_type":"code","source":"\"\"\"Here we chose add_11 layer.We can start to update weights after add_11 layer in training.\"\"\"\nlast_layer = base_model.get_layer(\"add_11\")\nprint(last_layer.output_shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-03T16:27:16.231736Z","iopub.execute_input":"2022-08-03T16:27:16.232974Z","iopub.status.idle":"2022-08-03T16:27:16.241599Z","shell.execute_reply.started":"2022-08-03T16:27:16.232922Z","shell.execute_reply":"2022-08-03T16:27:16.239958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = os.listdir(images_dir)\n\"\"\"BatchNormalization and GlobalAveragePooling to reduce input dim to 1D.\"\"\"\nx = tf.keras.layers.BatchNormalization()(last_layer.output)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\n\"\"\"Fully connected layer.\"\"\"\nx = tf.keras.layers.Dense(128,activation = \"relu\")(x)\n\"\"\"Dropout layer\"\"\"\nx = tf.keras.layers.Dropout(0.3)(x)\n\"\"\"Output layer\"\"\"\nx = tf.keras.layers.Dense(len(classes),activation = \"softmax\")(x)\n\"\"\"Finally,we can connect model end to end.\"\"\"\nmodel = tf.keras.models.Model(base_model.input,x)","metadata":{"execution":{"iopub.status.busy":"2022-08-03T16:27:17.422392Z","iopub.execute_input":"2022-08-03T16:27:17.423567Z","iopub.status.idle":"2022-08-03T16:27:17.51424Z","shell.execute_reply.started":"2022-08-03T16:27:17.423481Z","shell.execute_reply":"2022-08-03T16:27:17.512868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-03T16:27:18.419134Z","iopub.execute_input":"2022-08-03T16:27:18.419516Z","iopub.status.idle":"2022-08-03T16:27:18.443619Z","shell.execute_reply.started":"2022-08-03T16:27:18.41946Z","shell.execute_reply":"2022-08-03T16:27:18.44261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**COMPILE AND FIT MODEL**","metadata":{}},{"cell_type":"code","source":"model.compile(tf.keras.optimizers.Adam(learning_rate = 0.001),loss = \"categorical_crossentropy\",metrics = [\"acc\"])\n\"\"\"Callback class.\"\"\"\nclass myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self,epoch,logs = {}):\n        if epoch >= 10 and logs.get(\"acc\") - logs.get(\"val_acc\") >= 0.1:\n            self.model.stop_training = True\n            print(\"Model tends to be overfitting.Stop training.\")\n        elif logs.get(\"acc\") > 0.95:\n            self.model.stop_training = True\n            print(\"Model tends to be overfitting.Stop training.\")\ncallback = myCallback()\n        ","metadata":{"execution":{"iopub.status.busy":"2022-08-05T08:55:18.981612Z","iopub.execute_input":"2022-08-05T08:55:18.982071Z","iopub.status.idle":"2022-08-05T08:55:19.021315Z","shell.execute_reply.started":"2022-08-05T08:55:18.982033Z","shell.execute_reply":"2022-08-05T08:55:19.020263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_generator,epochs = 30,batch_size = 32,validation_data = validation_generator,\n                   callbacks = [callback],verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-08-05T08:55:19.818236Z","iopub.execute_input":"2022-08-05T08:55:19.818598Z","iopub.status.idle":"2022-08-05T09:26:15.25883Z","shell.execute_reply.started":"2022-08-05T08:55:19.818568Z","shell.execute_reply":"2022-08-05T09:26:15.257781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**PLOT ACCURACY AND LOSS**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nacc = history.history[\"acc\"]\nval_acc = history.history[\"val_acc\"]\nepochs = range(11)\nplt.plot(epochs,acc,label = \"Training Accuracy\")\nplt.plot(epochs,val_acc,label = \"Validation Accuracy\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-05T09:33:09.578905Z","iopub.execute_input":"2022-08-05T09:33:09.579294Z","iopub.status.idle":"2022-08-05T09:33:09.786567Z","shell.execute_reply.started":"2022-08-05T09:33:09.579261Z","shell.execute_reply":"2022-08-05T09:33:09.785559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = history.history[\"loss\"]\nval_loss = history.history[\"val_loss\"]\nepochs = range(11)\nplt.plot(epochs,loss,label = \"Training Loss\")\nplt.plot(epochs,val_loss,label = \"Validation Loss\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-05T09:33:16.433623Z","iopub.execute_input":"2022-08-05T09:33:16.433983Z","iopub.status.idle":"2022-08-05T09:33:16.649071Z","shell.execute_reply.started":"2022-08-05T09:33:16.433952Z","shell.execute_reply":"2022-08-05T09:33:16.648141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SAVE AND LOAD MODEL**","metadata":{}},{"cell_type":"code","source":"model.save(\"animal_classify_TFL.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-08-03T16:38:41.961337Z","iopub.execute_input":"2022-08-03T16:38:41.962013Z","iopub.status.idle":"2022-08-03T16:38:42.295169Z","shell.execute_reply.started":"2022-08-03T16:38:41.961974Z","shell.execute_reply":"2022-08-03T16:38:42.294091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = tf.keras.models.load_model(\"animal_classify_TFL.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-08-03T16:39:06.815065Z","iopub.execute_input":"2022-08-03T16:39:06.815445Z","iopub.status.idle":"2022-08-03T16:39:07.791531Z","shell.execute_reply.started":"2022-08-03T16:39:06.815413Z","shell.execute_reply":"2022-08-03T16:39:07.790605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**GET THE IMAGES FROM INTERNET AND PROCESS THEM TO PREDICT**","metadata":{}},{"cell_type":"code","source":"from PIL import Image\nimport requests\nfrom io import BytesIO\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-08-03T16:35:44.979076Z","iopub.execute_input":"2022-08-03T16:35:44.979983Z","iopub.status.idle":"2022-08-03T16:35:44.987554Z","shell.execute_reply.started":"2022-08-03T16:35:44.979944Z","shell.execute_reply":"2022-08-03T16:35:44.986539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_and_process(url):\n    response = requests.get(url)\n    img = Image.open(BytesIO(response.content))\n    img1 = img\n    \"\"\"Resize img to proper shape for model.\"\"\"\n    img = img.resize((150,150))\n    \"\"\"Convert img to numpy array,rescale it,expand dims and check vertically.\"\"\"\n    x = tf.keras.preprocessing.image.img_to_array(img)\n    x = x / 255\n    x = np.expand_dims(x,axis = 0)\n    img_tensor = np.vstack([x])\n    return img1,img_tensor","metadata":{"execution":{"iopub.status.busy":"2022-08-03T16:39:10.960871Z","iopub.execute_input":"2022-08-03T16:39:10.961242Z","iopub.status.idle":"2022-08-03T16:39:10.968862Z","shell.execute_reply.started":"2022-08-03T16:39:10.961211Z","shell.execute_reply":"2022-08-03T16:39:10.967838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**FINAL : PREDICT IMAGE**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ntranslate = {\"cane\": \"dog\", \"cavallo\": \"horse\", \"elefante\": \"elephant\", \"farfalla\": \"butterfly\", \"gallina\": \"chicken\",\n             \"gatto\": \"cat\", \"mucca\": \"cow\", \"pecora\": \"sheep\", \"scoiattolo\": \"squirrel\", \"dog\": \"cane\",\n             \"cavallo\": \"horse\", \"elephant\" : \"elefante\", \"butterfly\": \"farfalla\", \"chicken\": \"gallina\", \"cat\": \"gatto\", \n             \"cow\": \"mucca\", \"spider\": \"ragno\", \"squirrel\": \"scoiattolo\"}\n\nurl = \"https://i.natgeofe.com/k/ff49e0e1-20b6-4c4b-84c8-4ad196e312e4/eastern-gray-squirrel-closeup_square.jpg\"\nimg1,test_img = get_and_process(url)\npred = model1.predict(test_img)\nclasses = list(train_generator.class_indices.keys())\nprint(f\"Prediction is : {translate[classes[np.argmax(pred)]]}\")\nplt.imshow(img1)\nplt.show()\nprint(pred)\nprint(classes)","metadata":{"execution":{"iopub.status.busy":"2022-08-03T16:45:01.430406Z","iopub.execute_input":"2022-08-03T16:45:01.431219Z","iopub.status.idle":"2022-08-03T16:45:03.519952Z","shell.execute_reply.started":"2022-08-03T16:45:01.431165Z","shell.execute_reply":"2022-08-03T16:45:03.518423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}